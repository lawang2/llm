{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fc5bde60-1899-461d-8083-3ee04ac7c099",
   "metadata": {},
   "source": [
    "# 模型推理 - 使用 QLoRA 微调后的 ChatGLM-6B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3292b88c-91f0-48d2-91a5-06b0830c7e70",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoModel, AutoTokenizer, BitsAndBytesConfig\n",
    "\n",
    "# 模型ID或本地路径\n",
    "model_name_or_path = 'THUDM/chatglm3-6b'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f81454c-24b2-4072-ab05-b25f9b120ae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "_compute_dtype_map = {\n",
    "    'fp32': torch.float32,\n",
    "    'fp16': torch.float16,\n",
    "    'bf16': torch.bfloat16\n",
    "}\n",
    "\n",
    "# QLoRA 量化配置\n",
    "q_config = BitsAndBytesConfig(load_in_4bit=True,\n",
    "                              bnb_4bit_quant_type='nf4',\n",
    "                              bnb_4bit_use_double_quant=True,\n",
    "                              bnb_4bit_compute_dtype=_compute_dtype_map['bf16'])\n",
    "\n",
    "# 加载量化后模型(与微调的 revision 保持一致）\n",
    "base_model = AutoModel.from_pretrained(model_name_or_path,\n",
    "                                      quantization_config=q_config,\n",
    "                                      device_map='auto',\n",
    "                                      trust_remote_code=True,\n",
    "                                      revision='b098244')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d488846f-41bb-4fe6-9f09-0f392f3b39e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model.requires_grad_(False)\n",
    "base_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7e4270e2-c827-450e-bf27-7cb43a97f8f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_name_or_path,\n",
    "                                          trust_remote_code=True,\n",
    "                                          revision='b098244')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63408b60-876e-4eda-b501-90f842cca002",
   "metadata": {},
   "source": [
    "## 使用原始 ChatGLM3-6B 模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6ef405cf-7d77-41a6-a07b-c6c768ee30cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_text = \"解释下乾卦是什么？\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "566ed80e-828b-4105-b6e6-49de8905c991",
   "metadata": {},
   "outputs": [],
   "source": [
    "response, history = base_model.chat(tokenizer, query=input_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cee217e-f276-4c2f-94e7-69afb6d541a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3db3245d-037d-4fe5-ac0d-cc5e82742399",
   "metadata": {},
   "source": [
    "#### 询问一个64卦相关问题（应该不在 ChatGLM3-6B 预训练数据中）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbe1395f-39c2-4759-ae81-90ef3bcfae47",
   "metadata": {},
   "outputs": [],
   "source": [
    "response, history = base_model.chat(tokenizer, query=\"周易中的讼卦是什么？\", history=history)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d23e720-dee1-4b43-a298-0cbe1d8ad11d",
   "metadata": {},
   "source": [
    "## 使用微调后的 ChatGLM3-6B"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bcfc5a2-41ed-405c-a31c-dca4fbb67425",
   "metadata": {},
   "source": [
    "### 加载 QLoRA Adapter(Epoch=3, automade-dataset(fixed)) - 请根据训练时间戳修改 timestamp "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9c767c67-42aa-459c-a096-e226226c359b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft import PeftModel, PeftConfig\n",
    "\n",
    "epochs = 3\n",
    "# TODO 这个地方需要根据文件qlora_chatglm3_timestamp-hw.ipynb中训练出来的模型的存储文件内容来选填\n",
    "timestamp = \"20250520_222843\"\n",
    "\n",
    "peft_model_path = f\"models/{model_name_or_path}-epoch{epochs}-{timestamp}\"\n",
    "\n",
    "config = PeftConfig.from_pretrained(peft_model_path)\n",
    "qlora_model = PeftModel.from_pretrained(base_model, peft_model_path)\n",
    "training_tag=f\"ChatGLM3-6B(Epoch=3, automade-dataset(fixed))-{timestamp}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "24a5d22b-2c94-4dcf-8135-18d78f98755f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_chatglm_results(query, base_model, qlora_model, training_tag):\n",
    "    base_response, base_history = base_model.chat(tokenizer, query)\n",
    "\n",
    "    inputs = tokenizer(query, return_tensors=\"pt\").to(0)\n",
    "    ft_out = qlora_model.generate(**inputs, max_new_tokens=512)\n",
    "    ft_response = tokenizer.decode(ft_out[0], skip_special_tokens=True)\n",
    "    \n",
    "    print(f\"问题：{query}\\n\\n原始输出：\\n{base_response}\\n\\n\\n微调后（{training_tag}）：\\n{ft_response}\")\n",
    "    return base_response, ft_response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "062cd62e-69f9-4605-8c83-e468f71ef3d3",
   "metadata": {},
   "source": [
    "### 微调前后效果对比"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7db16cd5-0bb5-44ab-b861-d9ca6a4970c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_response, ft_response = compare_chatglm_results(\"解释下乾卦是什么？\", base_model, qlora_model, training_tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aa074bd-c819-4533-a10f-f3184dc9549a",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_response, ft_response = compare_chatglm_results(\"周易中的讼卦是什么\", base_model, qlora_model, training_tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5a31554-40f1-4e6e-8240-f207c4a61b42",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_response, ft_response = compare_chatglm_results(\"师卦是什么？\", base_model, qlora_model, training_tag)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d48183f-f1dc-4171-b217-e269a5b9c1b9",
   "metadata": {},
   "source": [
    "## 其他模型（错误数据或训练参数）\n",
    "\n",
    "#### 加载 QLoRA Adapter(Epoch=3, automade-dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "46a0e881-a4f3-43b2-8a61-0ec543a538a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft import PeftModel, PeftConfig\n",
    "\n",
    "epochs = 3\n",
    "peft_model_path = f\"models/{model_name_or_path}-epoch{epochs}\"\n",
    "\n",
    "config = PeftConfig.from_pretrained(peft_model_path)\n",
    "qlora_model_e3 = PeftModel.from_pretrained(base_model, peft_model_path)\n",
    "training_tag = f\"ChatGLM3-6B(Epoch=3, automade-dataset)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f53196e-f523-4105-b04a-9ddab349cce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_response, ft_response = compare_chatglm_results(\"解释下乾卦是什么？\", base_model, qlora_model_e3, training_tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "046306ad-6afe-4ec9-ae55-3df04f61d8f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_response, ft_response = compare_chatglm_results(\"地水师卦是什么？\", base_model, qlora_model_e3, training_tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ab3c310-8cc8-428a-91fa-964b7a58df43",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_response, ft_response = compare_chatglm_results(\"周易中的讼卦是什么\", base_model, qlora_model_e3, training_tag)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8169237c-55d3-4d91-9f6b-8dbe635f1844",
   "metadata": {},
   "source": [
    "#### 加载 QLoRA Adapter(Epoch=50, Overfit, handmade-dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "72e6cc4f-c030-4107-b07a-6ef44f66a4b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 过拟合\n",
    "from peft import PeftModel, PeftConfig\n",
    "\n",
    "epochs = 50\n",
    "peft_model_path = f\"models/{model_name_or_path}-epoch{epochs}\"\n",
    "\n",
    "config = PeftConfig.from_pretrained(peft_model_path)\n",
    "qlora_model_e50_handmade = PeftModel.from_pretrained(base_model, peft_model_path)\n",
    "training_tag = f\"ChatGLM3-6B(Epoch=50, handmade-dataset)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d63b187-37be-4721-8959-098d0437c41d",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_response, ft_response = compare_chatglm_results(\"解释下乾卦是什么？\", base_model, qlora_model_e50_handmade, training_tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be5da80e-d1de-467f-a3bb-508d5a77a46d",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_response, ft_response = compare_chatglm_results(\"地水师卦\", base_model, qlora_model_e50_handmade, training_tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04f0eb9a-5075-4588-914a-2538bea801aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_response, ft_response = compare_chatglm_results(\"天水讼卦\", base_model, qlora_model_e50_handmade, training_tag)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
