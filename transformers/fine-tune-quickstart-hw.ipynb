{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 基于transformers实现模型微调训练的主要流程，包括：\n",
    "- 数据集下载\n",
    "- 数据预处理\n",
    "- 训练超参数配置\n",
    "- 训练评估指标设置\n",
    "- 训练器基本介绍\n",
    "- 实战训练\n",
    "- 模型保存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "### import pkgs\n",
    "from datasets import load_dataset\n",
    "\n",
    "import random\n",
    "import pandas as pd\n",
    "import datasets\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "from transformers import TrainingArguments, Trainer\n",
    "import numpy as np\n",
    "import evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#base \n",
    "model_dir = \"models/bert-base-cased-finetune-yelp\"\n",
    "model_name_or_path = \"hugging face model file path\" # TODO\n",
    "\n",
    "## function\n",
    "def show_random_elements(dataset, num_examples=10):\n",
    "    assert num_examples <= len(dataset), \"Can't pick more elements than there are in the dataset.\"\n",
    "\n",
    "    picks = []\n",
    "    for _ in range(num_examples):\n",
    "        pick = random.randint(0, len(dataset)-1)\n",
    "        while pick in picks:\n",
    "            pick = random.randint(0, len(dataset)-1)\n",
    "        picks.append(pick)\n",
    "\n",
    "    df = pd.DataFrame(dataset[picks])\n",
    "    for column, typ in dataset.features.items():\n",
    "        if isinstance(typ, datasets.ClassLabel):\n",
    "            df[column]=df[column].transform(lambda i: typ.names[i])\n",
    "    display(HTML(df.to_html()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 下载数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 手动下载模型，使用huggingface-cli\n",
    "# huggingface-cli download --resume-download bert-base-cased --local-dir bert-base-cased\n",
    "dataset = load_dataset(\"yelp_review_full\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['label', 'text'],\n",
       "        num_rows: 650000\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['label', 'text'],\n",
       "        num_rows: 50000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'label': 0,\n",
       " 'text': 'My expectations for McDonalds are t rarely high. But for one to still fail so spectacularly...that takes something special!\\\\nThe cashier took my friends\\'s order, then promptly ignored me. I had to force myself in front of a cashier who opened his register to wait on the person BEHIND me. I waited over five minutes for a gigantic order that included precisely one kid\\'s meal. After watching two people who ordered after me be handed their food, I asked where mine was. The manager started yelling at the cashiers for \\\\\"serving off their orders\\\\\" when they didn\\'t have their food. But neither cashier was anywhere near those controls, and the manager was the one serving food to customers and clearing the boards.\\\\nThe manager was rude when giving me my order. She didn\\'t make sure that I had everything ON MY RECEIPT, and never even had the decency to apologize that I felt I was getting poor service.\\\\nI\\'ve eaten at various McDonalds restaurants for over 30 years. I\\'ve worked at more than one location. I expect bad days, bad moods, and the occasional mistake. But I have yet to have a decent experience at this store. It will remain a place I avoid unless someone in my party needs to avoid illness from low blood sugar. Perhaps I should go back to the racially biased service of Steak n Shake instead!'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[\"train\"][100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4 stars</td>\n",
       "      <td>Good food but you'll be surprised by your bill. Go to share a small order of fries with your small burger...seriously.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5 stars</td>\n",
       "      <td>Just got done eating the most delicious Veggie Benny at Egg Works. I can never eat breakfast anywhere but here. There food is always so scrumptious and there staff is super friendly. Speaking of staff, Donna is quite the wonderful waitress. She was fun and attentive to our needs. We didn't even have to wait for a refill. I can't wait to come back next weekend.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4 stars</td>\n",
       "      <td>Love this place...but I love frozen yogurt in general.\\n\\nThey have yogurt. They have toppings.\\nThat's what you want when you want frozen yogurt, right?\\n\\nIf you're at the mall, why not stop by?\\n\\nWhy then did I rate this place so high since it's your typical frozen yogurt place?\\nFor the taro.\\n\\nNo other frozen yogurt place that I've frequented around here offers that flavor. If I could just have taro,  I would! If you haven't tried it, please do.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1 star</td>\n",
       "      <td>I was in Las Vegas for my daughter's wedding.  I arrived with plenty of time to grab my reserved rental car.  There were about 15 people in line at the Payless counter and nobody at any of the other counters.  I though ok, this won't take too long because there were three agents taking care of customers.  There were two employees alerting Nevada residents that they needed an alternative proof of address other then their drivers licenses.  This of course, made people angry because who is going to bring their bank statements, which they suggested, to the airport with them?  Each agent also spent at least 20 minutes with each customer. The whole time there was a woman at the little EZ car rental business, who like a carnival barker, was yelling that there are no lines at EZ Car, get your car fast here. You don't need two forms of ID here!  This barking was pretty much continuous during my entire hour wait. The EZ car rental was 1 station carved out of the end of the Payless counter.\\n\\nRight before it was my turn at the counter, while the people in the line were audibly complaining, calling customer service on their phones, etc., I noticed that the woman carnival barking for EZ Car kept going over to the Payless agents with paperwork as if they all worked for the same place.  I was kind of confused.  It dawned on me at that point that this company manufactures customer dissatisfaction in order to encourage customers to switch over to the \\\"other\\\" easy car rental place, but without their pre-reserved on line discounts.  I have a very strong suspicion that they are one and the same company.\\n\\nAt this point I was really cutting it close to being late for my daughter's wedding.  Finally my turn, I walked up to the agent with drivers license, credit card, and reservation in hand and immediately explained that I didn't have time to talk at the counter for 20 minutes because I would be late for the wedding.  She immediately informed me that there would be many questions she would have to ask me before she could rent me a car.  I told her that I just want the car with no added insurance and I was in a hurry.  Then she immediately told me that she couldn't rent me a car because I was being abusive!\\n\\nThis made me absolutely furious.  I got my credit card and license back from her and went over to Enterprise, and not the \\\"other\\\" company at the end of their counter.  It took about three minutes there.  As I walked past Payless the people who were behind me in line were still chatting at the counter.  Happy to say that I made it to the wedding on time.   Avoid Payless at all costs.  Not sure if what they're doing is legal, but it sure smells like fraud to me.\\n\\nI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2 star</td>\n",
       "      <td>Stayed here overnight on trip back to California.\\n\\nPros:\\n- Complementary breakfast\\n- Free Wi-Fi\\n- Comfortable beds &amp; decent size room.\\n- Spacious entry &amp; nice modern look.\\n\\nCons:\\n- Crazy small parking lot with almost no room! Had to park next to someone already double parked.\\n- Hard to access with one way streets on each side.\\n- * Free shuttle to the strip was nice, but they didn't pick up at the stated time, nor in the spot they said the would. We arrived 10 minutes before the said arrival at the Tropicanna (where they said they pick up) and they never came for the last pick up. I had to call the hotel. Al they said was they had already been there and would not come back. \\n- Noisy from airport\\n\\nThe bottom line:\\nNot a good shuttle service. Decent rooms but shuttle service was aweful! Felt like they lied to me. Left 4 of us to take a cab back. Sucks.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4 stars</td>\n",
       "      <td>Amazing customer service, workers here actually care about helping you out! I was looking for an uncommon tri-wing screwdriver here and Maria (I believe this is her name) hunted down the someone who might know where to find it, and got back to me promptly. A++ WOULD SHOP AGAIN!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3 stars</td>\n",
       "      <td>Had to stay here for couple hours while waiting for a flight back home.. it was okay.. nice clean and had plenty of restaurants and bars to choose from..</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3 stars</td>\n",
       "      <td>about 3.5 stars\\n\\nhands down much better than tao beach. that place doesn't let you drink while you're in the water, lame! and tao beach is tiny. granted, i didn't go to wet republic here, just their regular pools outside, but i think it was nice.\\n\\nmy friend and i bought our own drinks at fat tuesday, i got a 1/2 yard and she got a huge mug and met up with other friends at this pool. thanks goodness for knowing someone with a room key! i believe it's the only way to get in for free. it was great b.c they already had seats, which were in a shaded area.\\n\\nnow for the pool: once you step in, it's pretty refreshing. it may be a little too crowded, but get that and that fact that you are stewing in everyone's mess out of your mind, and you can have a pretty good time. i guess it doesn't help to have a couple drinks in hand.\\n\\nbeware: don't taste or swallow the water! i got some splashed on my face, and the shit tasted like nothing but salty nastiness. good thing i had my 1/2 yard to wash that down with the awesome taste of sin city juice.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2 star</td>\n",
       "      <td>Noisy.\\n\\nLimited menu.\\n\\nControlled chaotic restaurant environment.\\n\\nTook forever to get a table, so we left.\\n\\nWent to the Breakfast Club in Scottsdale.  Nice location, seating outdoors, and food that rivals Matt's.\\n\\nNo longer have any reason or desire to go back to Matt's.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3 stars</td>\n",
       "      <td>Had this for take out the first time a couple months ago when we had a pizza craving. The place seemed pretty spacious and great for a kid's birthday party or family gathering. The pizza was okay. The cinnamon pie/roll/sticks thing was AMAZING. But other than that, I thought it was pretty meh.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_random_elements(dataset[\"train\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 预处理数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ecs-user/miniconda3/envs/llm/lib/python3.10/site-packages/huggingface_hub/file_download.py:943: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "483dda66c75f49a99cfedc0a9d936fdc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/50000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#tokenizer = AutoTokenizer.from_pretrained(model_name_or_path)\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-cased\")\n",
    "\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[\"text\"], padding = \"max_length\", truncation=True)\n",
    "\n",
    "\n",
    "tokenized_datasets = dataset.map(tokenize_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>input_ids</th>\n",
       "      <th>token_type_ids</th>\n",
       "      <th>attention_mask</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2 star</td>\n",
       "      <td>This joint is pretty average and so is their food . \\n\\n\\nThere is maybe around 6-7 choices of hot dogs and this definitely cannot satisfy everyone's taste --restaurant should consider doing custom orders.\\n\\nAnywho , my Morgan freeman tasted good but the overall experience was average and at that price (close to 10$) I was expecting a lot better . For example , the restaurant could have given us a fries or a drink through such an expensive order . Come the heck on it's a hot dog , will you seriously charge me 10$ ? Even Japadog in Vancouver makes better hot dogs in term of taste and friendly prices .\\n\\nService was courteous , but cooking these took a while , walking in such a joint makes you think you can get out with your food in 10 mins but it is certainly not the case as it took close to 20 mins .\\n\\nAnyway , if you really crave for a hot dog on mont royal you can definitely come to this joint , it's an experience nonetheless. However , note that they are not great and are certainly overpriced . You can definitely get better and more of them at Julep or Decarie hot dogs if you are willing to make the Trip</td>\n",
       "      <td>[101, 1188, 4091, 1110, 2785, 1903, 1105, 1177, 1110, 1147, 2094, 119, 165, 183, 165, 183, 165, 183, 1942, 12807, 1110, 2654, 1213, 127, 118, 128, 9940, 1104, 2633, 6363, 1105, 1142, 5397, 2834, 13692, 2490, 112, 188, 5080, 118, 118, 4382, 1431, 4615, 1833, 8156, 3791, 119, 165, 183, 165, 183, 1592, 3382, 2246, 5114, 117, 1139, 4461, 1714, 1399, 12876, 1363, 1133, 1103, 2905, 2541, 1108, 1903, 1105, 1120, 1115, 3945, 113, 1601, 1106, 1275, 109, 114, 146, 1108, 7805, 170, 1974, 1618, 119, 1370, 1859, 117, 1103, 4382, 1180, 1138, 1549, 1366, 170, 175, 3377, 1137, 170, ...]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...]</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_random_elements(tokenized_datasets[\"train\"], num_examples=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 数据抽样\n",
    "\n",
    "# shuffle()函数会随机重新排列列的值。如果您希望对用于洗牌数据集的算法有更多控制，可以在此函数中指定generator参数来使用不同的numpy.random.Generator。\n",
    "\n",
    "small_train_dataset = tokenized_datasets[\"train\"].shuffle(seed=42).select(range(1000))\n",
    "small_eval_dataset = tokenized_datasets[\"test\"].shuffle(seed=42).select(range(1000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 微调训练配置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(\"bert-base-cased\", num_labels=5)\n",
    "#model = AutoModelForSequenceClassification.from_pretrained(model_name_or_path, num_labels=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TrainingArguments(\n",
      "_n_gpu=1,\n",
      "adafactor=False,\n",
      "adam_beta1=0.9,\n",
      "adam_beta2=0.999,\n",
      "adam_epsilon=1e-08,\n",
      "auto_find_batch_size=False,\n",
      "bf16=False,\n",
      "bf16_full_eval=False,\n",
      "data_seed=None,\n",
      "dataloader_drop_last=False,\n",
      "dataloader_num_workers=0,\n",
      "dataloader_persistent_workers=False,\n",
      "dataloader_pin_memory=True,\n",
      "ddp_backend=None,\n",
      "ddp_broadcast_buffers=None,\n",
      "ddp_bucket_cap_mb=None,\n",
      "ddp_find_unused_parameters=None,\n",
      "ddp_timeout=1800,\n",
      "debug=[],\n",
      "deepspeed=None,\n",
      "disable_tqdm=False,\n",
      "dispatch_batches=None,\n",
      "do_eval=False,\n",
      "do_predict=False,\n",
      "do_train=False,\n",
      "eval_accumulation_steps=None,\n",
      "eval_delay=0,\n",
      "eval_steps=None,\n",
      "evaluation_strategy=no,\n",
      "fp16=False,\n",
      "fp16_backend=auto,\n",
      "fp16_full_eval=False,\n",
      "fp16_opt_level=O1,\n",
      "fsdp=[],\n",
      "fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False},\n",
      "fsdp_min_num_params=0,\n",
      "fsdp_transformer_layer_cls_to_wrap=None,\n",
      "full_determinism=False,\n",
      "gradient_accumulation_steps=1,\n",
      "gradient_checkpointing=False,\n",
      "gradient_checkpointing_kwargs=None,\n",
      "greater_is_better=None,\n",
      "group_by_length=False,\n",
      "half_precision_backend=auto,\n",
      "hub_always_push=False,\n",
      "hub_model_id=None,\n",
      "hub_private_repo=False,\n",
      "hub_strategy=every_save,\n",
      "hub_token=<HUB_TOKEN>,\n",
      "ignore_data_skip=False,\n",
      "include_inputs_for_metrics=False,\n",
      "include_num_input_tokens_seen=False,\n",
      "include_tokens_per_second=False,\n",
      "jit_mode_eval=False,\n",
      "label_names=None,\n",
      "label_smoothing_factor=0.0,\n",
      "learning_rate=5e-05,\n",
      "length_column_name=length,\n",
      "load_best_model_at_end=False,\n",
      "local_rank=0,\n",
      "log_level=passive,\n",
      "log_level_replica=warning,\n",
      "log_on_each_node=True,\n",
      "logging_dir=models/bert-base-cased-finetune-yelp/runs/May26_11-45-24_ubuntu-lesleyll,\n",
      "logging_first_step=False,\n",
      "logging_nan_inf_filter=True,\n",
      "logging_steps=100,\n",
      "logging_strategy=steps,\n",
      "lr_scheduler_kwargs={},\n",
      "lr_scheduler_type=linear,\n",
      "max_grad_norm=1.0,\n",
      "max_steps=-1,\n",
      "metric_for_best_model=None,\n",
      "mp_parameters=,\n",
      "neftune_noise_alpha=None,\n",
      "no_cuda=False,\n",
      "num_train_epochs=5,\n",
      "optim=adamw_torch,\n",
      "optim_args=None,\n",
      "output_dir=models/bert-base-cased-finetune-yelp,\n",
      "overwrite_output_dir=False,\n",
      "past_index=-1,\n",
      "per_device_eval_batch_size=8,\n",
      "per_device_train_batch_size=16,\n",
      "prediction_loss_only=False,\n",
      "push_to_hub=False,\n",
      "push_to_hub_model_id=None,\n",
      "push_to_hub_organization=None,\n",
      "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
      "ray_scope=last,\n",
      "remove_unused_columns=True,\n",
      "report_to=[],\n",
      "resume_from_checkpoint=None,\n",
      "run_name=models/bert-base-cased-finetune-yelp,\n",
      "save_on_each_node=False,\n",
      "save_only_model=False,\n",
      "save_safetensors=True,\n",
      "save_steps=500,\n",
      "save_strategy=steps,\n",
      "save_total_limit=None,\n",
      "seed=42,\n",
      "skip_memory_metrics=True,\n",
      "split_batches=False,\n",
      "tf32=None,\n",
      "torch_compile=False,\n",
      "torch_compile_backend=None,\n",
      "torch_compile_mode=None,\n",
      "torchdynamo=None,\n",
      "tpu_metrics_debug=False,\n",
      "tpu_num_cores=None,\n",
      "use_cpu=False,\n",
      "use_ipex=False,\n",
      "use_legacy_prediction_loop=False,\n",
      "use_mps_device=False,\n",
      "warmup_ratio=0.0,\n",
      "warmup_steps=0,\n",
      "weight_decay=0.0,\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# 最重要配置：模型权重保存路径（output_dir）\n",
    "\n",
    "training_args = TrainingArguments(output_dir=model_dir,\n",
    "                                  per_device_train_batch_size=16,\n",
    "                                  num_train_epochs=5,\n",
    "                                  logging_steps=100)\n",
    "\n",
    "print(training_args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 训练过程中的指标评估（Evaluate）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import evaluate\n",
    "\n",
    "metric = evaluate.load(\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    return metric.compute(predictions=predictions,references=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 训练过程指标监控\n",
    "training_args = TrainingArguments(output_dir=model_dir,\n",
    "                                  evaluation_strategy=\"epoch\", \n",
    "                                  per_device_train_batch_size=16,\n",
    "                                  num_train_epochs=3,\n",
    "                                  logging_steps=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 开始训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(model=model,\n",
    "                  args=training_args,\n",
    "                  train_dataset=small_train_dataset,\n",
    "                  eval_dataset=small_eval_dataset,\n",
    "                  compute_metrics=compute_metrics)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='189' max='189' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [189/189 01:58, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.471900</td>\n",
       "      <td>1.198524</td>\n",
       "      <td>0.487000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.994000</td>\n",
       "      <td>1.026885</td>\n",
       "      <td>0.561000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.694500</td>\n",
       "      <td>0.947726</td>\n",
       "      <td>0.584000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=189, training_loss=1.0942042113611938, metrics={'train_runtime': 119.7812, 'train_samples_per_second': 25.046, 'train_steps_per_second': 1.578, 'total_flos': 789354427392000.0, 'train_loss': 1.0942042113611938, 'epoch': 3.0})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用nvidia-smi查看GPU的使用\n",
    "!watch -n 1 nvidia-smi\n",
    "\n",
    "Every 1.0s: nvidia-smi                                                                                                                                                                         ubuntu-lesleyll: Mon May 26 11:52:19 2025\n",
    "\n",
    "Mon May 26 11:52:19 2025\n",
    "+-----------------------------------------------------------------------------------------+\n",
    "| NVIDIA-SMI 550.127.08             Driver Version: 550.127.08     CUDA Version: 12.4     |\n",
    "|-----------------------------------------+------------------------+----------------------+\n",
    "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
    "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
    "|                                         |                        |               MIG M. |\n",
    "|=========================================+========================+======================|\n",
    "|   0  Tesla V100-SXM2-16GB           On  |   00000000:00:07.0 Off |                    0 |\n",
    "| N/A   36C    P0             55W /  300W |   12137MiB /  16384MiB |      0%      Default |\n",
    "|                                         |                        |                  N/A |\n",
    "+-----------------------------------------+------------------------+----------------------+\n",
    "\n",
    "+-----------------------------------------------------------------------------------------+\n",
    "| Processes:                                                                              |\n",
    "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
    "|        ID   ID                                                               Usage      |\n",
    "|=========================================================================================|\n",
    "|    0   N/A  N/A     11119      C   ...user/miniconda3/envs/llm/bin/python      12134MiB |\n",
    "+-----------------------------------------------------------------------------------------+\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='13' max='13' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [13/13 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.9957807064056396,\n",
       " 'eval_accuracy': 0.53,\n",
       " 'eval_runtime': 1.0787,\n",
       " 'eval_samples_per_second': 92.704,\n",
       " 'eval_steps_per_second': 12.051,\n",
       " 'epoch': 3.0}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 测试\n",
    "\n",
    "small_test_dataset = tokenized_datasets[\"test\"].shuffle(seed=64).select(range(100))\n",
    "\n",
    "trainer.evaluate(small_test_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 保存模型和训练状态"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_model(model_dir)\n",
    "trainer.save_state()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Homework:使用完整的yelpReviewFull数据集训练，看看ACC最高到多少"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# : Homework:使用完整的yelpReviewFull数据集训练bert-base-cased模型，看看ACC最高到多少\n",
    "metric = evaluate.load(\"accuracy\")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    return metric.compute(predictions=predictions,references=labels)\n",
    "\n",
    "training_args = TrainingArguments(output_dir=model_dir,\n",
    "                                  evaluation_strategy=\"epoch\",             # 每个 epoch 评估一次\n",
    "                                  per_device_train_batch_size=16,\n",
    "                                  num_train_epochs=3,\n",
    "                                  save_total_limit=1,                      # 最多只保留最近一个 checkpoint，旧的会自动删除\n",
    "                                  logging_strategy=\"steps\",                # 使用步数方式控制日志\n",
    "                                  logging_steps=1000,                      # 每 n 步记录一次日志（降低频率）\n",
    "                                  load_best_model_at_end=False,            # 不保存最优模型（省空间；如需调优再打开）\n",
    "                                  fp16=True,                               # 如果支持 GPU，建议开启混合精度训练，节省显存+提速\n",
    "                                  )  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "large_train_dataset = tokenized_datasets[\"train\"].shuffle(seed=42).select(range(100000))\n",
    "#large_eval_dataset = tokenized_datasets[\"test\"].shuffle(seed=42).select(range(1000))\n",
    "\n",
    "#full_train_dataset = tokenized_datasets[\"train\"]\n",
    "full_eval_dataset = tokenized_datasets[\"test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='18750' max='18750' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [18750/18750 1:16:29, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.797095</td>\n",
       "      <td>0.653620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.767100</td>\n",
       "      <td>0.798259</td>\n",
       "      <td>0.664780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.767100</td>\n",
       "      <td>0.935516</td>\n",
       "      <td>0.659720</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checkpoint destination directory models/bert-base-cased-finetune-yelp/checkpoint-500 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=18750, training_loss=0.6514964583333334, metrics={'train_runtime': 4590.1639, 'train_samples_per_second': 65.357, 'train_steps_per_second': 4.085, 'total_flos': 7.89354427392e+16, 'train_loss': 0.6514964583333334, 'epoch': 3.0})"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer = Trainer(model=model,\n",
    "                  args=training_args,\n",
    "                  train_dataset=large_train_dataset,\n",
    "                  eval_dataset=full_eval_dataset,\n",
    "                  compute_metrics=compute_metrics)\n",
    "\n",
    "trainer.train() ## 查看 training loss 和 validation loss 和 accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6250' max='6250' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6250/6250 04:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.9355159997940063,\n",
       " 'eval_accuracy': 0.65972,\n",
       " 'eval_runtime': 242.906,\n",
       " 'eval_samples_per_second': 205.841,\n",
       " 'eval_steps_per_second': 25.73,\n",
       " 'epoch': 3.0}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 测试\n",
    "\n",
    "#large_test_dataset = tokenized_datasets[\"test\"].shuffle(seed=64).select(range(30000))\n",
    "full_test_dataset = tokenized_datasets[\"test\"]\n",
    "trainer.evaluate(full_test_dataset) ## 查看 test loss 和 accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (llm)",
   "language": "python",
   "name": "llm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
